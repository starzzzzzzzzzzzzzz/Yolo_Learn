# YOLO è®­ç»ƒå®æˆ˜æŒ‡å—

è¿™ä»½æŒ‡å—å°†æ‰‹æŠŠæ‰‹æ•™ä½ å¦‚ä½•è®­ç»ƒè‡ªå·±çš„ YOLO æ¨¡å‹ï¼ˆé‡ç‚¹æ˜¯ YOLOv8ï¼‰ã€‚

---

## ç›®å½•

1. [ç¯å¢ƒå‡†å¤‡](#1-ç¯å¢ƒå‡†å¤‡)
2. [æ•°æ®é›†å‡†å¤‡](#2-æ•°æ®é›†å‡†å¤‡)
3. [æ•°æ®æ ‡æ³¨](#3-æ•°æ®æ ‡æ³¨)
4. [YOLOv8 è®­ç»ƒ](#4-yolov8-è®­ç»ƒ)
5. [æ¨¡å‹è¯„ä¼°](#5-æ¨¡å‹è¯„ä¼°)
6. [æ¨¡å‹ä¼˜åŒ–](#6-æ¨¡å‹ä¼˜åŒ–)
7. [æ¨¡å‹éƒ¨ç½²](#7-æ¨¡å‹éƒ¨ç½²)
8. [å¸¸è§é—®é¢˜](#8-å¸¸è§é—®é¢˜)

---

## 1. ç¯å¢ƒå‡†å¤‡

### 1.1 ç¡¬ä»¶è¦æ±‚

**æœ€ä½é…ç½®:**
- CPU: 4 æ ¸å¿ƒ
- RAM: 8GB
- GPU: 4GB æ˜¾å­˜ï¼ˆå¯é€‰ï¼Œä½†å¼ºçƒˆæ¨èï¼‰
- ç¡¬ç›˜: 50GB å¯ç”¨ç©ºé—´

**æ¨èé…ç½®:**
- CPU: 8 æ ¸å¿ƒæˆ–æ›´å¤š
- RAM: 16GB æˆ–æ›´å¤š
- GPU: NVIDIA GPU (8GB+ æ˜¾å­˜)
  - å…¥é—¨: RTX 3060 (12GB)
  - æ¨è: RTX 3080 (10GB)
  - ç†æƒ³: RTX 3090/4090 æˆ– A100
- ç¡¬ç›˜: SSD 100GB+

### 1.2 è½¯ä»¶å®‰è£…

#### æ­¥éª¤ 1: å®‰è£… Python

```bash
# æ¨èä½¿ç”¨ Python 3.8 - 3.11
python --version
```

#### æ­¥éª¤ 2: åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ

```bash
# ä½¿ç”¨ conda
conda create -n yolo python=3.10
conda activate yolo

# æˆ–ä½¿ç”¨ venv
python -m venv yolo_env
source yolo_env/bin/activate  # Linux/Mac
# yolo_env\Scripts\activate  # Windows
```

#### æ­¥éª¤ 3: å®‰è£… PyTorch

è®¿é—® https://pytorch.org/get-started/locally/ è·å–é€‚åˆä½ ç³»ç»Ÿçš„å‘½ä»¤

```bash
# CUDA 11.8 ç¤ºä¾‹
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# CPU ç‰ˆæœ¬ï¼ˆä¸æ¨èï¼Œè®­ç»ƒä¼šå¾ˆæ…¢ï¼‰
pip install torch torchvision torchaudio
```

#### æ­¥éª¤ 4: å®‰è£… YOLOv8

```bash
pip install ultralytics
```

#### æ­¥éª¤ 5: éªŒè¯å®‰è£…

```python
# test_install.py
import torch
from ultralytics import YOLO

print(f"PyTorch ç‰ˆæœ¬: {torch.__version__}")
print(f"CUDA å¯ç”¨: {torch.cuda.is_available()}")
if torch.cuda.is_available():
    print(f"CUDA ç‰ˆæœ¬: {torch.version.cuda}")
    print(f"GPU: {torch.cuda.get_device_name(0)}")

# æµ‹è¯• YOLOv8
model = YOLO('yolov8n.pt')
print("âœ… YOLOv8 å®‰è£…æˆåŠŸï¼")
```

### 1.3 å¯é€‰å·¥å…·

```bash
# æ•°æ®æ ‡æ³¨å·¥å…·
pip install labelimg  # æˆ–ä½¿ç”¨ LabelMe, CVAT

# å¯è§†åŒ–å·¥å…·
pip install tensorboard
pip install wandb  # Weights & Biases

# å›¾åƒå¤„ç†
pip install opencv-python pillow
pip install albumentations
```

---

## 2. æ•°æ®é›†å‡†å¤‡

### 2.1 æ•°æ®é›†ç»“æ„

YOLO éœ€è¦ç‰¹å®šçš„ç›®å½•ç»“æ„ï¼š

```
my_dataset/
â”œâ”€â”€ images/
â”‚   â”œâ”€â”€ train/
â”‚   â”‚   â”œâ”€â”€ img1.jpg
â”‚   â”‚   â”œâ”€â”€ img2.jpg
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ val/
â”‚   â”‚   â”œâ”€â”€ img100.jpg
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ test/  (å¯é€‰)
â”‚       â””â”€â”€ ...
â”œâ”€â”€ labels/
â”‚   â”œâ”€â”€ train/
â”‚   â”‚   â”œâ”€â”€ img1.txt
â”‚   â”‚   â”œâ”€â”€ img2.txt
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ val/
â”‚   â”‚   â”œâ”€â”€ img100.txt
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ test/  (å¯é€‰)
â”‚       â””â”€â”€ ...
â””â”€â”€ data.yaml
```

### 2.2 åˆ›å»º data.yaml

```yaml
# data.yaml
path: /path/to/my_dataset  # æ•°æ®é›†æ ¹ç›®å½•
train: images/train        # è®­ç»ƒé›†è·¯å¾„ï¼ˆç›¸å¯¹äº pathï¼‰
val: images/val            # éªŒè¯é›†è·¯å¾„
test: images/test          # æµ‹è¯•é›†è·¯å¾„ï¼ˆå¯é€‰ï¼‰

# ç±»åˆ«
nc: 3  # ç±»åˆ«æ•°é‡
names: ['cat', 'dog', 'bird']  # ç±»åˆ«åç§°ï¼ˆç´¢å¼•å¯¹åº” 0, 1, 2...ï¼‰
```

### 2.3 æ•°æ®æ”¶é›†å»ºè®®

#### æ•°é‡å»ºè®®:
- **æœ€å°‘**: æ¯ç±» 100-200 å¼ 
- **æ¨è**: æ¯ç±» 500-1000 å¼ 
- **ç†æƒ³**: æ¯ç±» 1000-5000 å¼ 

#### è´¨é‡è¦æ±‚:
1. **å¤šæ ·æ€§**
   - ä¸åŒå…‰ç…§æ¡ä»¶ï¼ˆç™½å¤©ã€å¤œæ™šã€å®¤å†…ã€å®¤å¤–ï¼‰
   - ä¸åŒè§’åº¦ï¼ˆæ­£é¢ã€ä¾§é¢ã€ä¿¯è§†ã€ä»°è§†ï¼‰
   - ä¸åŒè·ç¦»ï¼ˆè¿‘æ™¯ã€ä¸­æ™¯ã€è¿œæ™¯ï¼‰
   - ä¸åŒèƒŒæ™¯
   - ä¸åŒå§¿æ€/çŠ¶æ€

2. **å›¾åƒè´¨é‡**
   - æ¸…æ™°åº¦ï¼šé¿å…æ¨¡ç³Š
   - åˆ†è¾¨ç‡ï¼šè‡³å°‘ 640Ã—640
   - æ ¼å¼ï¼šJPG, PNG
   - é¿å…è¿‡åº¦å‹ç¼©

3. **æ ‡æ³¨è´¨é‡**
   - å‡†ç¡®çš„è¾¹ç•Œæ¡†
   - æ­£ç¡®çš„ç±»åˆ«æ ‡ç­¾
   - å®Œæ•´æ ‡æ³¨ï¼ˆä¸é—æ¼ç›®æ ‡ï¼‰
   - ä¸€è‡´çš„æ ‡æ³¨æ ‡å‡†

#### æ•°æ®æ¥æº:
- è‡ªå·±æ‹æ‘„ï¼ˆæœ€å¥½ï¼‰
- å…¬å¼€æ•°æ®é›†
  - COCO: https://cocodataset.org/
  - Open Images: https://storage.googleapis.com/openimages/web/index.html
  - Pascal VOC: http://host.robots.ox.ac.uk/pascal/VOC/
- çˆ¬è™«é‡‡é›†ï¼ˆæ³¨æ„ç‰ˆæƒï¼‰
- æ•°æ®å¢å¼ºï¼ˆæ‰©å……æ•°æ®ï¼‰

### 2.4 æ•°æ®åˆ’åˆ†

```python
# split_dataset.py
import os
import shutil
from pathlib import Path
import random

def split_dataset(image_dir, train_ratio=0.8, val_ratio=0.1, test_ratio=0.1):
    """
    åˆ’åˆ†æ•°æ®é›†ä¸ºè®­ç»ƒé›†ã€éªŒè¯é›†å’Œæµ‹è¯•é›†
    """
    assert train_ratio + val_ratio + test_ratio == 1.0
    
    # è·å–æ‰€æœ‰å›¾åƒ
    images = list(Path(image_dir).glob('*.jpg')) + \
             list(Path(image_dir).glob('*.png'))
    
    # æ‰“ä¹±
    random.shuffle(images)
    
    # è®¡ç®—åˆ’åˆ†ç‚¹
    n = len(images)
    train_end = int(n * train_ratio)
    val_end = train_end + int(n * val_ratio)
    
    # åˆ’åˆ†
    train_images = images[:train_end]
    val_images = images[train_end:val_end]
    test_images = images[val_end:]
    
    # åˆ›å»ºç›®å½•
    base_dir = Path(image_dir).parent
    for split in ['train', 'val', 'test']:
        (base_dir / 'images' / split).mkdir(parents=True, exist_ok=True)
        (base_dir / 'labels' / split).mkdir(parents=True, exist_ok=True)
    
    # å¤åˆ¶æ–‡ä»¶
    def copy_files(image_list, split):
        for img_path in image_list:
            # å¤åˆ¶å›¾åƒ
            shutil.copy(img_path, base_dir / 'images' / split / img_path.name)
            
            # å¤åˆ¶æ ‡ç­¾
            label_path = img_path.with_suffix('.txt')
            if label_path.exists():
                shutil.copy(label_path, base_dir / 'labels' / split / label_path.name)
    
    copy_files(train_images, 'train')
    copy_files(val_images, 'val')
    copy_files(test_images, 'test')
    
    print(f"âœ… æ•°æ®é›†åˆ’åˆ†å®Œæˆ:")
    print(f"   è®­ç»ƒé›†: {len(train_images)} å¼ ")
    print(f"   éªŒè¯é›†: {len(val_images)} å¼ ")
    print(f"   æµ‹è¯•é›†: {len(test_images)} å¼ ")

# ä½¿ç”¨ç¤ºä¾‹
split_dataset('/path/to/all_images', train_ratio=0.8, val_ratio=0.1, test_ratio=0.1)
```

---

## 3. æ•°æ®æ ‡æ³¨

### 3.1 YOLO æ ‡æ³¨æ ¼å¼

æ¯ä¸ªå›¾åƒå¯¹åº”ä¸€ä¸ªåŒåçš„ `.txt` æ–‡ä»¶ï¼Œæ¯è¡Œè¡¨ç¤ºä¸€ä¸ªç›®æ ‡ï¼š

```
<class_id> <x_center> <y_center> <width> <height>
```

- `class_id`: ç±»åˆ«ç´¢å¼•ï¼ˆä» 0 å¼€å§‹ï¼‰
- `x_center`: è¾¹ç•Œæ¡†ä¸­å¿ƒ x åæ ‡ï¼ˆå½’ä¸€åŒ–åˆ° [0, 1]ï¼‰
- `y_center`: è¾¹ç•Œæ¡†ä¸­å¿ƒ y åæ ‡ï¼ˆå½’ä¸€åŒ–åˆ° [0, 1]ï¼‰
- `width`: è¾¹ç•Œæ¡†å®½åº¦ï¼ˆå½’ä¸€åŒ–åˆ° [0, 1]ï¼‰
- `height`: è¾¹ç•Œæ¡†é«˜åº¦ï¼ˆå½’ä¸€åŒ–åˆ° [0, 1]ï¼‰

**ç¤ºä¾‹:**
```
0 0.5 0.5 0.3 0.4
1 0.2 0.3 0.15 0.2
```

### 3.2 æ ‡æ³¨å·¥å…·

#### LabelImg (æ¨èæ–°æ‰‹)

```bash
pip install labelimg
labelimg
```

**ä½¿ç”¨æ­¥éª¤:**
1. æ‰“å¼€ç›®å½•
2. é€‰æ‹© "PascalVOC" æˆ– "YOLO" æ ¼å¼
3. æŒ‰ `W` é”®å¼€å§‹æ ‡æ³¨
4. æ‹–åŠ¨æ¡†é€‰ç›®æ ‡
5. é€‰æ‹©ç±»åˆ«
6. æŒ‰ `Ctrl+S` ä¿å­˜
7. æŒ‰ `D` é”®ä¸‹ä¸€å¼ å›¾

#### Roboflow (åœ¨çº¿å·¥å…·)

https://roboflow.com/

**ä¼˜åŠ¿:**
- åœ¨çº¿åä½œ
- è‡ªåŠ¨æ•°æ®å¢å¼º
- å¯¼å‡ºå¤šç§æ ¼å¼
- æ•°æ®é›†ç‰ˆæœ¬ç®¡ç†

#### CVAT (ä¸“ä¸šå·¥å…·)

https://www.cvat.ai/

**ä¼˜åŠ¿:**
- æ”¯æŒå›¢é˜Ÿåä½œ
- è§†é¢‘æ ‡æ³¨
- åŠè‡ªåŠ¨æ ‡æ³¨
- è´¨é‡æ§åˆ¶

### 3.3 æ ‡æ³¨è´¨é‡æ£€æŸ¥

```python
# check_annotations.py
import cv2
from pathlib import Path

def visualize_annotations(image_dir, label_dir, class_names):
    """
    å¯è§†åŒ–æ ‡æ³¨ç»“æœï¼Œæ£€æŸ¥è´¨é‡
    """
    image_files = list(Path(image_dir).glob('*.jpg'))
    
    for img_path in image_files:
        # è¯»å–å›¾åƒ
        img = cv2.imread(str(img_path))
        h, w = img.shape[:2]
        
        # è¯»å–æ ‡ç­¾
        label_path = Path(label_dir) / f"{img_path.stem}.txt"
        if not label_path.exists():
            print(f"âš ï¸ ç¼ºå°‘æ ‡ç­¾: {img_path.name}")
            continue
        
        with open(label_path, 'r') as f:
            for line in f:
                parts = line.strip().split()
                if len(parts) != 5:
                    print(f"âš ï¸ æ ¼å¼é”™è¯¯: {label_path.name} - {line}")
                    continue
                
                cls_id, x_c, y_c, box_w, box_h = map(float, parts)
                
                # è½¬æ¢ä¸ºåƒç´ åæ ‡
                x1 = int((x_c - box_w/2) * w)
                y1 = int((y_c - box_h/2) * h)
                x2 = int((x_c + box_w/2) * w)
                y2 = int((y_c + box_h/2) * h)
                
                # æ£€æŸ¥åæ ‡èŒƒå›´
                if x1 < 0 or y1 < 0 or x2 > w or y2 > h:
                    print(f"âš ï¸ åæ ‡è¶Šç•Œ: {img_path.name}")
                
                # ç»˜åˆ¶
                cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)
                label = class_names[int(cls_id)]
                cv2.putText(img, label, (x1, y1-10), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)
        
        # æ˜¾ç¤º
        cv2.imshow('Annotation Check', img)
        key = cv2.waitKey(0)
        if key == ord('q'):
            break
    
    cv2.destroyAllWindows()

# ä½¿ç”¨
class_names = ['cat', 'dog', 'bird']
visualize_annotations('images/train', 'labels/train', class_names)
```

---

## 4. YOLOv8 è®­ç»ƒ

### 4.1 åŸºç¡€è®­ç»ƒ

```python
# train.py
from ultralytics import YOLO

# åŠ è½½é¢„è®­ç»ƒæ¨¡å‹
model = YOLO('yolov8n.pt')  # n, s, m, l, x

# å¼€å§‹è®­ç»ƒ
results = model.train(
    data='data.yaml',       # æ•°æ®é…ç½®æ–‡ä»¶
    epochs=100,             # è®­ç»ƒè½®æ•°
    imgsz=640,              # è¾“å…¥å›¾åƒå°ºå¯¸
    batch=16,               # æ‰¹æ¬¡å¤§å°
    name='my_experiment',   # å®éªŒåç§°
    device=0,               # GPU è®¾å¤‡ ID (æˆ– 'cpu')
)
```

### 4.2 å®Œæ•´è®­ç»ƒé…ç½®

```python
# train_advanced.py
from ultralytics import YOLO

model = YOLO('yolov8m.pt')

results = model.train(
    # ===== æ•°æ®é…ç½® =====
    data='data.yaml',
    
    # ===== è®­ç»ƒé…ç½® =====
    epochs=300,              # è®­ç»ƒè½®æ•°
    patience=50,             # æ—©åœè€å¿ƒå€¼
    batch=32,                # æ‰¹æ¬¡å¤§å°ï¼ˆæ ¹æ® GPU å†…å­˜è°ƒæ•´ï¼‰
    imgsz=640,               # è¾“å…¥å°ºå¯¸ (640, 1280...)
    save=True,               # ä¿å­˜æ£€æŸ¥ç‚¹
    save_period=10,          # æ¯ N è½®ä¿å­˜ä¸€æ¬¡ (-1=åªä¿å­˜æœ€å)
    cache='ram',             # ç¼“å­˜å›¾åƒ (False, 'ram', 'disk')
    device=0,                # GPU ID æˆ– 'cpu'
    workers=8,               # æ•°æ®åŠ è½½å™¨çº¿ç¨‹æ•°
    project='runs/train',    # é¡¹ç›®ç›®å½•
    name='custom_model',     # å®éªŒåç§°
    exist_ok=False,          # è¦†ç›–ç°æœ‰å®éªŒ
    pretrained=True,         # ä½¿ç”¨é¢„è®­ç»ƒæƒé‡
    optimizer='SGD',         # ä¼˜åŒ–å™¨ (SGD, Adam, AdamW, NAdam, RAdam, RMSProp)
    verbose=True,            # è¯¦ç»†è¾“å‡º
    seed=0,                  # éšæœºç§å­
    deterministic=True,      # ç¡®å®šæ€§æ¨¡å¼
    single_cls=False,        # å•ç±»åˆ«è®­ç»ƒ
    rect=False,              # çŸ©å½¢è®­ç»ƒ
    cos_lr=False,            # ä½™å¼¦å­¦ä¹ ç‡
    close_mosaic=10,         # æœ€å N è½®å…³é—­ mosaic
    resume=False,            # æ¢å¤è®­ç»ƒ
    amp=True,                # è‡ªåŠ¨æ··åˆç²¾åº¦
    fraction=1.0,            # ä½¿ç”¨æ•°æ®é›†çš„æ¯”ä¾‹ (0.0-1.0)
    profile=False,           # æ€§èƒ½åˆ†æ
    
    # ===== è¶…å‚æ•° =====
    lr0=0.01,                # åˆå§‹å­¦ä¹ ç‡
    lrf=0.01,                # æœ€ç»ˆå­¦ä¹ ç‡ (lr0 * lrf)
    momentum=0.937,          # SGD momentum / Adam beta1
    weight_decay=0.0005,     # æƒé‡è¡°å‡
    warmup_epochs=3.0,       # warmup è½®æ•°
    warmup_momentum=0.8,     # warmup åˆå§‹ momentum
    warmup_bias_lr=0.1,      # warmup åˆå§‹ bias å­¦ä¹ ç‡
    box=7.5,                 # è¾¹ç•Œæ¡†æŸå¤±æƒé‡
    cls=0.5,                 # åˆ†ç±»æŸå¤±æƒé‡
    dfl=1.5,                 # DFL æŸå¤±æƒé‡
    pose=12.0,               # å§¿æ€æŸå¤±æƒé‡ï¼ˆä»…å§¿æ€ï¼‰
    kobj=2.0,                # å…³é”®ç‚¹ç›®æ ‡æŸå¤±æƒé‡
    label_smoothing=0.0,     # æ ‡ç­¾å¹³æ»‘ (0.0-1.0)
    nbs=64,                  # åä¹‰æ‰¹æ¬¡å¤§å°
    overlap_mask=True,       # è®­ç»ƒæ—¶ mask æ˜¯å¦é‡å 
    mask_ratio=4,            # mask ä¸‹é‡‡æ ·æ¯”ç‡
    dropout=0.0,             # ä½¿ç”¨ dropout æ­£åˆ™åŒ–
    val=True,                # è®­ç»ƒæ—¶éªŒè¯
    
    # ===== æ•°æ®å¢å¼º =====
    hsv_h=0.015,             # HSV-Hue å¢å¼º
    hsv_s=0.7,               # HSV-Saturation å¢å¼º
    hsv_v=0.4,               # HSV-Value å¢å¼º
    degrees=0.0,             # æ—‹è½¬è§’åº¦ (+/- deg)
    translate=0.1,           # å¹³ç§» (+/- æ¯”ä¾‹)
    scale=0.5,               # ç¼©æ”¾å¢ç›Š (+/- æ¯”ä¾‹)
    shear=0.0,               # å‰ªåˆ‡è§’åº¦ (+/- deg)
    perspective=0.0,         # é€è§†å˜æ¢ (+/- æ¯”ä¾‹)
    flipud=0.0,              # ä¸Šä¸‹ç¿»è½¬æ¦‚ç‡
    fliplr=0.5,              # å·¦å³ç¿»è½¬æ¦‚ç‡
    mosaic=1.0,              # Mosaic å¢å¼ºæ¦‚ç‡
    mixup=0.0,               # MixUp å¢å¼ºæ¦‚ç‡
    copy_paste=0.0,          # Copy-paste å¢å¼ºæ¦‚ç‡
)

print("è®­ç»ƒå®Œæˆï¼")
print(f"æœ€ä½³æ¨¡å‹: {results.save_dir}/weights/best.pt")
```

### 4.3 ä»æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒ

```python
# æ¢å¤è®­ç»ƒ
model = YOLO('runs/train/custom_model/weights/last.pt')
results = model.train(resume=True)
```

### 4.4 ç›‘æ§è®­ç»ƒè¿›ç¨‹

#### æ–¹æ³• 1: TensorBoard

```bash
# è®­ç»ƒæ—¶è‡ªåŠ¨ç”Ÿæˆ TensorBoard æ—¥å¿—
tensorboard --logdir runs/train
```

#### æ–¹æ³• 2: Weights & Biases

```python
# é›†æˆ W&B
import wandb

wandb.login()

model = YOLO('yolov8n.pt')
results = model.train(
    data='data.yaml',
    epochs=100,
    project='my_yolo_project',  # W&B ä¼šè‡ªåŠ¨è®°å½•
)
```

### 4.5 è®­ç»ƒæŠ€å·§

#### æŠ€å·§ 1: å­¦ä¹ ç‡è°ƒä¼˜

```python
# ä½¿ç”¨å­¦ä¹ ç‡æŸ¥æ‰¾å™¨
model = YOLO('yolov8n.pt')

# å…ˆç”¨å°å­¦ä¹ ç‡è®­ç»ƒå‡ è½®ï¼Œè§‚å¯ŸæŸå¤±
# ç„¶åé€æ­¥å¢åŠ å­¦ä¹ ç‡
```

#### æŠ€å·§ 2: æ¸è¿›å¼è®­ç»ƒ

```python
# é˜¶æ®µ 1: å†»ç»“éª¨å¹²ï¼Œåªè®­ç»ƒå¤´éƒ¨
model = YOLO('yolov8n.pt')
results = model.train(
    data='data.yaml',
    epochs=50,
    freeze=10,  # å†»ç»“å‰ 10 å±‚
)

# é˜¶æ®µ 2: å…¨æ¨¡å‹è®­ç»ƒ
results = model.train(
    data='data.yaml',
    epochs=150,
    freeze=0,
)
```

#### æŠ€å·§ 3: å¤šGPU è®­ç»ƒ

```python
# ä½¿ç”¨å¤šä¸ª GPU
model = YOLO('yolov8n.pt')
results = model.train(
    data='data.yaml',
    epochs=100,
    device=[0, 1, 2, 3],  # ä½¿ç”¨ GPU 0-3
    batch=64,  # æ€»æ‰¹æ¬¡å¤§å°ä¼šåˆ†é…åˆ°æ‰€æœ‰ GPU
)
```

---

## 5. æ¨¡å‹è¯„ä¼°

### 5.1 éªŒè¯æ¨¡å‹

```python
# validate.py
from ultralytics import YOLO

model = YOLO('runs/train/custom_model/weights/best.pt')

# åœ¨éªŒè¯é›†ä¸Šè¯„ä¼°
metrics = model.val()

# æ‰“å°æŒ‡æ ‡
print(f"mAP50-95: {metrics.box.map}")
print(f"mAP50: {metrics.box.map50}")
print(f"mAP75: {metrics.box.map75}")
print(f"å„ç±»åˆ« mAP50-95: {metrics.box.maps}")
```

### 5.2 æµ‹è¯•é›†æ¨ç†

```python
# test.py
from ultralytics import YOLO
import cv2

model = YOLO('runs/train/custom_model/weights/best.pt')

# å•å¼ å›¾åƒ
results = model('test_image.jpg')

# æ‰¹é‡å›¾åƒ
results = model(['img1.jpg', 'img2.jpg', 'img3.jpg'])

# ä¿å­˜ç»“æœ
for i, result in enumerate(results):
    result.save(f'output_{i}.jpg')
    
    # æˆ–æ‰‹åŠ¨å¤„ç†
    boxes = result.boxes
    for box in boxes:
        x1, y1, x2, y2 = box.xyxy[0]
        conf = box.conf[0]
        cls = box.cls[0]
        print(f"æ£€æµ‹: ç±»åˆ«={int(cls)}, ç½®ä¿¡åº¦={conf:.2f}, "
              f"ä½ç½®=({x1:.0f},{y1:.0f},{x2:.0f},{y2:.0f})")
```

### 5.3 è¯„ä¼°æŒ‡æ ‡è¯¦è§£

```python
# analyze_metrics.py
from ultralytics import YOLO
import matplotlib.pyplot as plt

model = YOLO('runs/train/custom_model/weights/best.pt')
metrics = model.val()

# ä¸»è¦æŒ‡æ ‡
print("=" * 50)
print("æ¨¡å‹æ€§èƒ½æŒ‡æ ‡")
print("=" * 50)
print(f"mAP50-95 (ä¸»è¦æŒ‡æ ‡): {metrics.box.map:.4f}")
print(f"mAP50: {metrics.box.map50:.4f}")
print(f"mAP75: {metrics.box.map75:.4f}")
print(f"ç²¾ç¡®ç‡ (Precision): {metrics.box.mp:.4f}")
print(f"å¬å›ç‡ (Recall): {metrics.box.mr:.4f}")

# å„ç±»åˆ«æŒ‡æ ‡
print("\næ¯ä¸ªç±»åˆ«çš„ mAP50:")
for i, (name, ap) in enumerate(zip(model.names.values(), metrics.box.maps)):
    print(f"  {name}: {ap:.4f}")

# ä¸åŒå°ºå¯¸ç›®æ ‡çš„æ€§èƒ½
print(f"\nå°ç›®æ ‡ mAP: {metrics.box.map_small:.4f}")
print(f"ä¸­ç›®æ ‡ mAP: {metrics.box.map_medium:.4f}")
print(f"å¤§ç›®æ ‡ mAP: {metrics.box.map_large:.4f}")
```

### 5.4 æ··æ·†çŸ©é˜µåˆ†æ

è®­ç»ƒåä¼šè‡ªåŠ¨ç”Ÿæˆæ··æ·†çŸ©é˜µï¼š

```
runs/train/custom_model/confusion_matrix.png
```

åˆ†ææ··æ·†çŸ©é˜µå¯ä»¥å‘ç°ï¼š
- å“ªäº›ç±»åˆ«å®¹æ˜“æ··æ·†
- æ˜¯å¦æœ‰ç³»ç»Ÿæ€§é”™è¯¯
- éœ€è¦å¢åŠ å“ªäº›è®­ç»ƒæ•°æ®

---

## 6. æ¨¡å‹ä¼˜åŒ–

### 6.1 è¶…å‚æ•°è°ƒä¼˜

```python
# tune.py
from ultralytics import YOLO

model = YOLO('yolov8n.pt')

# è‡ªåŠ¨è¶…å‚æ•°è°ƒä¼˜ï¼ˆå®éªŒæ€§åŠŸèƒ½ï¼‰
results = model.tune(
    data='data.yaml',
    epochs=100,
    iterations=50,  # å°è¯•æ¬¡æ•°
    optimizer='AdamW',
    plots=True,
    save=True,
    val=True,
)
```

### 6.2 æ¨¡å‹å‰ªæ

```python
# ä½¿ç”¨æ›´å°çš„æ¨¡å‹
models = ['yolov8n.pt', 'yolov8s.pt', 'yolov8m.pt']

for model_name in models:
    model = YOLO(model_name)
    results = model.train(data='data.yaml', epochs=100)
    metrics = model.val()
    print(f"{model_name}: mAP={metrics.box.map:.4f}")
```

### 6.3 çŸ¥è¯†è’¸é¦ï¼ˆé«˜çº§ï¼‰

```python
# distillation.py
from ultralytics import YOLO

# æ•™å¸ˆæ¨¡å‹ï¼ˆå¤§æ¨¡å‹ï¼‰
teacher = YOLO('yolov8x.pt')
teacher.train(data='data.yaml', epochs=300)

# å­¦ç”Ÿæ¨¡å‹ï¼ˆå°æ¨¡å‹ï¼‰
student = YOLO('yolov8n.pt')

# ä½¿ç”¨æ•™å¸ˆæ¨¡å‹çš„é¢„æµ‹ä½œä¸ºè½¯æ ‡ç­¾
# ï¼ˆéœ€è¦è‡ªå®šä¹‰è®­ç»ƒå¾ªç¯ï¼Œè¿™é‡Œä»…ä¸ºæ¦‚å¿µç¤ºä¾‹ï¼‰
```

### 6.4 æ•°æ®å¢å¼ºè°ƒæ•´

```python
# å¦‚æœè¿‡æ‹Ÿåˆï¼Œå¢åŠ æ•°æ®å¢å¼º
results = model.train(
    data='data.yaml',
    epochs=100,
    mosaic=1.0,    # å§‹ç»ˆä½¿ç”¨ Mosaic
    mixup=0.2,     # 20% æ¦‚ç‡ä½¿ç”¨ MixUp
    hsv_h=0.02,    # å¢åŠ é¢œè‰²å¢å¼º
    hsv_s=0.8,
    hsv_v=0.5,
    degrees=10.0,  # å¢åŠ æ—‹è½¬
    scale=0.7,     # å¢åŠ ç¼©æ”¾èŒƒå›´
)

# å¦‚æœæ¬ æ‹Ÿåˆï¼Œå‡å°‘æ•°æ®å¢å¼º
results = model.train(
    data='data.yaml',
    epochs=100,
    mosaic=0.0,    # å…³é—­ Mosaic
    mixup=0.0,     # å…³é—­ MixUp
    degrees=0.0,   # å…³é—­æ—‹è½¬
)
```

---

## 7. æ¨¡å‹éƒ¨ç½²

### 7.1 å¯¼å‡ºæ¨¡å‹

```python
# export.py
from ultralytics import YOLO

model = YOLO('runs/train/custom_model/weights/best.pt')

# ===== ONNX (é€šç”¨) =====
model.export(format='onnx', simplify=True)

# ===== TensorRT (NVIDIA GPU) =====
model.export(format='engine', half=True, device=0)

# ===== CoreML (iOS/macOS) =====
model.export(format='coreml')

# ===== TFLite (ç§»åŠ¨ç«¯) =====
model.export(format='tflite')

# ===== OpenVINO (Intel) =====
model.export(format='openvino')

# ===== TorchScript =====
model.export(format='torchscript')
```

### 7.2 ONNX æ¨ç†

```python
# onnx_inference.py
import onnxruntime as ort
import numpy as np
import cv2

# åŠ è½½æ¨¡å‹
session = ort.InferenceSession('best.onnx')

# å‡†å¤‡è¾“å…¥
img = cv2.imread('test.jpg')
img = cv2.resize(img, (640, 640))
img = img.transpose(2, 0, 1)  # HWC -> CHW
img = np.expand_dims(img, 0)  # æ·»åŠ  batch ç»´åº¦
img = img.astype(np.float32) / 255.0

# æ¨ç†
input_name = session.get_inputs()[0].name
outputs = session.run(None, {input_name: img})

# å¤„ç†è¾“å‡º
print(f"è¾“å‡ºå½¢çŠ¶: {[out.shape for out in outputs]}")
```

### 7.3 TensorRT åŠ é€Ÿ

```python
# tensorrt_inference.py
from ultralytics import YOLO

# åŠ è½½ TensorRT æ¨¡å‹
model = YOLO('best.engine')

# æ¨ç†ï¼ˆè‡ªåŠ¨ä½¿ç”¨ TensorRTï¼‰
results = model('test.jpg')

# TensorRT é€šå¸¸æ¯” PyTorch å¿« 2-5 å€
```

### 7.4 å®æ—¶è§†é¢‘æ£€æµ‹

```python
# realtime_detection.py
from ultralytics import YOLO
import cv2

model = YOLO('best.pt')

# æ‰“å¼€æ‘„åƒå¤´
cap = cv2.VideoCapture(0)

while True:
    ret, frame = cap.read()
    if not ret:
        break
    
    # æ¨ç†
    results = model(frame)
    
    # ç»˜åˆ¶ç»“æœ
    annotated_frame = results[0].plot()
    
    # æ˜¾ç¤º
    cv2.imshow('YOLOv8 Detection', annotated_frame)
    
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()
```

### 7.5 Flask API éƒ¨ç½²

```python
# app.py
from flask import Flask, request, jsonify
from ultralytics import YOLO
from PIL import Image
import io

app = Flask(__name__)
model = YOLO('best.pt')

@app.route('/predict', methods=['POST'])
def predict():
    # æ¥æ”¶å›¾åƒ
    file = request.files['image']
    img = Image.open(io.BytesIO(file.read()))
    
    # æ¨ç†
    results = model(img)
    
    # æå–ç»“æœ
    detections = []
    for box in results[0].boxes:
        detections.append({
            'class': int(box.cls[0]),
            'confidence': float(box.conf[0]),
            'bbox': box.xyxy[0].tolist()
        })
    
    return jsonify({'detections': detections})

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5000)
```

---

## 8. å¸¸è§é—®é¢˜

### Q1: GPU æ˜¾å­˜ä¸è¶³æ€ä¹ˆåŠï¼Ÿ

**è§£å†³æ–¹æ¡ˆ:**
1. å‡å° `batch` å¤§å°
2. ä½¿ç”¨æ›´å°çš„æ¨¡å‹ (n < s < m < l < x)
3. é™ä½ `imgsz` (640 â†’ 512)
4. å…³é—­æ•°æ®ç¼“å­˜ (`cache=False`)
5. å¯ç”¨æ··åˆç²¾åº¦ (`amp=True`)

### Q2: mAP å¾ˆä½æ€ä¹ˆåŠï¼Ÿ

**æ£€æŸ¥æ¸…å•:**
1. æ•°æ®è´¨é‡
   - æ ‡æ³¨æ˜¯å¦å‡†ç¡®
   - ç±»åˆ«æ˜¯å¦å¹³è¡¡
   - æ•°æ®é‡æ˜¯å¦è¶³å¤Ÿ
2. è®­ç»ƒé…ç½®
   - epochs æ˜¯å¦è¶³å¤Ÿ (100+)
   - å­¦ä¹ ç‡æ˜¯å¦åˆé€‚
   - æ˜¯å¦ä½¿ç”¨é¢„è®­ç»ƒæƒé‡
3. æ•°æ®å¢å¼º
   - æ˜¯å¦è¿‡åº¦æˆ–ä¸è¶³
4. æ¨¡å‹é€‰æ‹©
   - æ¨¡å‹æ˜¯å¦å¤ªå°

### Q3: è®­ç»ƒå¾ˆæ…¢æ€ä¹ˆåŠï¼Ÿ

**ä¼˜åŒ–æ–¹æ³•:**
1. ä½¿ç”¨ GPU (`device=0`)
2. å¢åŠ  `workers` æ•°é‡
3. ç¼“å­˜æ•°æ®åˆ°å†…å­˜ (`cache='ram'`)
4. ä½¿ç”¨æ›´å°çš„å›¾åƒå°ºå¯¸
5. å‡å°‘æ•°æ®å¢å¼ºå¤æ‚åº¦

### Q4: è¿‡æ‹Ÿåˆæ€ä¹ˆåŠï¼Ÿ

**è§£å†³æ–¹æ¡ˆ:**
1. å¢åŠ è®­ç»ƒæ•°æ®
2. å¢å¼ºæ•°æ®å¢å¼º
   - `mosaic=1.0`
   - `mixup=0.2`
3. ä½¿ç”¨æ­£åˆ™åŒ–
   - `weight_decay=0.001`
   - `dropout=0.1`
4. æ—©åœ (`patience=50`)
5. ä½¿ç”¨æ›´å°çš„æ¨¡å‹

### Q5: æ¬ æ‹Ÿåˆæ€ä¹ˆåŠï¼Ÿ

**è§£å†³æ–¹æ¡ˆ:**
1. ä½¿ç”¨æ›´å¤§çš„æ¨¡å‹
2. å¢åŠ è®­ç»ƒè½®æ•°
3. æé«˜å­¦ä¹ ç‡
4. å‡å°‘æ•°æ®å¢å¼º
5. å‡å°‘æ­£åˆ™åŒ–

### Q6: æ¨ç†é€Ÿåº¦æ…¢æ€ä¹ˆåŠï¼Ÿ

**ä¼˜åŒ–æ–¹æ³•:**
1. ä½¿ç”¨ TensorRT (`format='engine'`)
2. ä½¿ç”¨ ONNX Runtime
3. é™ä½è¾“å…¥åˆ†è¾¨ç‡
4. ä½¿ç”¨æ›´å°çš„æ¨¡å‹
5. æ‰¹é‡æ¨ç†
6. åŠç²¾åº¦æ¨ç† (`half=True`)

### Q7: å°ç›®æ ‡æ£€æµ‹ä¸å¥½æ€ä¹ˆåŠï¼Ÿ

**æ”¹è¿›æ–¹æ³•:**
1. å¢åŠ è¾“å…¥å°ºå¯¸ (`imgsz=1280`)
2. ä½¿ç”¨æ›´å¤§çš„æ¨¡å‹
3. å¢åŠ å°ç›®æ ‡è®­ç»ƒæ ·æœ¬
4. ä½¿ç”¨ Mosaic å¢å¼º
5. è°ƒæ•´ anchor å°ºå¯¸

### Q8: å¦‚ä½•å¤„ç†ç±»åˆ«ä¸å¹³è¡¡ï¼Ÿ

**æ–¹æ³•:**
1. æ•°æ®å±‚é¢
   - è¿‡é‡‡æ ·å°‘æ•°ç±»
   - æ¬ é‡‡æ ·å¤šæ•°ç±»
   - æ•°æ®å¢å¼º
2. æŸå¤±å‡½æ•°
   - ç±»åˆ«æƒé‡
   - Focal Loss
3. åå¤„ç†
   - è°ƒæ•´ç½®ä¿¡åº¦é˜ˆå€¼

---

## æ€»ç»“

è¿™ä»½æŒ‡å—æ¶µç›–äº†ä»ç¯å¢ƒæ­å»ºåˆ°æ¨¡å‹éƒ¨ç½²çš„å®Œæ•´æµç¨‹ã€‚è®°ä½ï¼š

1. **æ•°æ®è´¨é‡ > æ¨¡å‹å¤æ‚åº¦**
   - é«˜è´¨é‡çš„æ ‡æ³¨
   - å……è¶³çš„æ•°æ®é‡
   - åˆç†çš„æ•°æ®å¢å¼º

2. **è¿­ä»£ä¼˜åŒ–**
   - ä»å°æ¨¡å‹å¼€å§‹
   - å¿«é€Ÿå®éªŒ
   - é€æ­¥æ”¹è¿›

3. **ç›‘æ§æŒ‡æ ‡**
   - å…³æ³¨ mAP50-95
   - æŸ¥çœ‹æ··æ·†çŸ©é˜µ
   - åˆ†æé”™è¯¯æ¡ˆä¾‹

4. **å®è·µä¸ºç‹**
   - å¤šå°è¯•ä¸åŒé…ç½®
   - è®°å½•å®éªŒç»“æœ
   - æ€»ç»“ç»éªŒæ•™è®­

ç¥ä½ è®­ç»ƒæˆåŠŸï¼ğŸ‰

---

## å‚è€ƒèµ„æº

- **YOLOv8 å®˜æ–¹æ–‡æ¡£**: https://docs.ultralytics.com
- **GitHub**: https://github.com/ultralytics/ultralytics
- **è®ºæ–‡**: https://arxiv.org/abs/...
- **ç¤¾åŒº**: https://community.ultralytics.com
- **æ•™ç¨‹**: https://docs.ultralytics.com/tutorials/

